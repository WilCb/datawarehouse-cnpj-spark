{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7f74eb-8adf-4a43-b995-282c3e648d5a",
   "metadata": {},
   "source": [
    "# Coletar dados de API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f021c23f",
   "metadata": {},
   "source": [
    "Este notebook realiza a extração dos dados via API pública e salva os dados na camada Landing (LND), no formato JSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b314a61a",
   "metadata": {},
   "source": [
    "## Importações e configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bb59398-629c-4225-b071-d666d8bb8ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import json\n",
    "import re\n",
    "import shutil\n",
    "import logging\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from typing import Any, List\n",
    "import requests\n",
    "from requests.exceptions import RequestException, HTTPError, Timeout, ConnectionError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c139de",
   "metadata": {},
   "source": [
    "## FUNÇÕES PARA EXTRAÇÃO DE DADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dd929de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria pasta de logs se ainda não existir\n",
    "os.makedirs(\"../LND/logs\", exist_ok=True)\n",
    "\n",
    "# Caminho do arquivo de log\n",
    "log_path = \"../LND/logs/download.log\"\n",
    "\n",
    "# Configura o logging para salvar no caminho desejado\n",
    "logging.basicConfig(\n",
    "    filename=log_path,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"  # \"w\" para sobrescrever sempre\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182a5d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_extract_files(file_list: List[str], month: str = \"2025-06\", base_dir: str = \"../LND\") -> None:\n",
    "    \"\"\"\n",
    "    Baixa e extrai arquivos .zip dos dados abertos da Receita Federal (CNPJ), organizando-os\n",
    "    por tipo e mês em uma estrutura de diretórios padronizada. Os arquivos extraídos são \n",
    "    renomeados com timestamp e logs são gerados em cada etapa do processo.\n",
    "\n",
    "    Args:\n",
    "        file_list (List[str]): Lista com os nomes dos arquivos .zip a serem baixados.\n",
    "        month (str, optional): Mês e ano dos dados no formato \"YYYY-MM\". Defaults to \"2025-06\".\n",
    "        base_dir (str, optional): Caminho base onde os arquivos serão armazenados. Defaults to \"../LND\".\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: Se a requisição do download falhar por erro HTTP.\n",
    "        ConnectionError | Timeout: Em caso de falha de rede ou tempo de resposta excedido.\n",
    "        RequestException: Para erros genéricos da biblioteca requests.\n",
    "        zipfile.BadZipFile: Se o arquivo zip estiver corrompido.\n",
    "        Exception: Para qualquer outro erro inesperado durante o processo.\n",
    "    \"\"\"\n",
    "    base_url = \"https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj\"\n",
    "\n",
    "    for zip_file_name in file_list:\n",
    "        try:\n",
    "            # Extrai o tipo do arquivo a partir do nome, ex: \"Empresas\", \"Cnaes\"\n",
    "            match = re.match(r\"([A-Za-z]+)\", zip_file_name)\n",
    "            file_type = match.group(1).lower() if match else \"outros\"\n",
    "\n",
    "            # Monta a URL completa para o download do arquivo\n",
    "            download_url = f\"{base_url}/{month}/{zip_file_name}\"\n",
    "\n",
    "            # Cria timestamp para nomear arquivos extraídos com unicidade\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "            # Define o diretório onde o arquivo será salvo, organizando por tipo e mês\n",
    "            output_dir = os.path.join(base_dir, file_type, month)\n",
    "\n",
    "            # Cria o diretório se não existir\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "            # Caminho completo do arquivo zip local para salvar/usar\n",
    "            local_zip_path = os.path.join(output_dir, zip_file_name)\n",
    "\n",
    "            # Verifica se o arquivo já foi baixado para evitar download repetido\n",
    "            if os.path.exists(local_zip_path):\n",
    "                msg = f\"Arquivo já existe, pulando download: {zip_file_name}\"\n",
    "                tqdm.write(msg)\n",
    "                logging.info(msg)\n",
    "            else:\n",
    "                # Informa início do download no console e no log\n",
    "                tqdm.write(\n",
    "                    f\"Iniciando download de {zip_file_name} de {download_url}\"\n",
    "                )\n",
    "                logging.info(\n",
    "                    f\"Iniciando download: {zip_file_name} de {download_url}\"\n",
    "                )\n",
    "\n",
    "                # Requisição HTTP para download com streaming (para não carregar tudo na memória)\n",
    "                response = requests.get(download_url, stream=True)\n",
    "\n",
    "                # Levanta exceção para erros HTTP\n",
    "                response.raise_for_status()\n",
    "\n",
    "                # Obtém o tamanho do arquivo para barra de progresso\n",
    "                file_size = int(response.headers.get(\"Content-Length\", 0))\n",
    "\n",
    "                # Abre arquivo local para escrita e exibe barra de progresso do tqdm\n",
    "                with open(local_zip_path, \"wb\") as f, tqdm(\n",
    "                    total=file_size,\n",
    "                    unit='B',\n",
    "                    unit_scale=True,\n",
    "                    desc=f\"Baixando {zip_file_name}\",\n",
    "                    ncols=80\n",
    "                ) as pbar:\n",
    "                    # Baixa em chunks e atualiza barra de progresso\n",
    "                    for chunk in response.iter_content(chunk_size=8192):\n",
    "                        if chunk:\n",
    "                            f.write(chunk)\n",
    "                            pbar.update(len(chunk))\n",
    "\n",
    "                # Log após download concluído com tamanho em MB\n",
    "                logging.info(\n",
    "                    f\"Download concluído: {zip_file_name} ({file_size / (1024**2):.2f} MB)\"\n",
    "                )\n",
    "\n",
    "            # Mensagem para extração do arquivo zip\n",
    "            tqdm.write(f\"Extraindo {zip_file_name}\")\n",
    "            logging.info(f\"Iniciando extração: {zip_file_name}\")\n",
    "\n",
    "            # Abre o arquivo zip baixado para extração\n",
    "            with zipfile.ZipFile(local_zip_path, \"r\") as zip_ref:\n",
    "\n",
    "                # Itera sobre os arquivos dentro do zip\n",
    "                for member in zip_ref.namelist():\n",
    "\n",
    "                    # Ignora pastas dentro do zip (nomes que terminam com '/')\n",
    "                    if not member.endswith(\"/\"):\n",
    "\n",
    "                        # Gera novo nome para o arquivo extraído com timestamp\n",
    "                        base_name = os.path.splitext(zip_file_name)[0]\n",
    "                        new_filename = f\"{base_name}_{timestamp}.csv\"\n",
    "                        final_path = os.path.join(output_dir, new_filename)\n",
    "\n",
    "                        # Copia o conteúdo extraído para o arquivo final (em blocos para evitar uso excessivo de memória)\n",
    "                        with zip_ref.open(member) as source, open(final_path, \"wb\") as target:\n",
    "                            shutil.copyfileobj(\n",
    "                                source, target, length=1024 * 1024\n",
    "                            )\n",
    "\n",
    "                        # Informações de sucesso no console e log\n",
    "                        tqdm.write(\n",
    "                            f\"Arquivo extraído e salvo como: {final_path}\"\n",
    "                        )\n",
    "                        logging.info(f\"Arquivo extraído e salvo: {final_path}\")\n",
    "\n",
    "            # Após extração bem-sucedida, remove o arquivo zip para liberar espaço\n",
    "            os.remove(local_zip_path)\n",
    "            tqdm.write(f\"ZIP removido: {zip_file_name}\")\n",
    "            logging.info(f\"ZIP removido: {zip_file_name}\")\n",
    "\n",
    "        # Tratamento de exceção para arquivos zip corrompidos\n",
    "        except zipfile.BadZipFile as badzip:\n",
    "            logging.error(\n",
    "                f\"Arquivo .zip corrompido: {zip_file_name} - {badzip}\")\n",
    "\n",
    "            # Remove o zip corrompido para tentar baixar novamente depois\n",
    "            if os.path.exists(local_zip_path):\n",
    "                os.remove(local_zip_path)\n",
    "            continue  # Pula para o próximo arquivo\n",
    "\n",
    "        # Tratamento para erros HTTP durante o download\n",
    "        except HTTPError as http_err:\n",
    "            logging.error(f\"[HTTP ERROR] {response.status_code} - {http_err}\")\n",
    "            raise\n",
    "\n",
    "        # Tratamento para erros de conexão ou timeout na rede\n",
    "        except (ConnectionError, Timeout) as conn_err:\n",
    "            logging.error(f\"[ERRO DE CONEXÃO] - {conn_err}\")\n",
    "            raise\n",
    "\n",
    "        # Tratamento para erros genéricos da biblioteca requests\n",
    "        except RequestException as req_err:\n",
    "            logging.error(f\"[REQUEST ERROR] - {req_err}\")\n",
    "            raise\n",
    "\n",
    "        # Captura e loga qualquer outro erro inesperado\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Erro inesperado ao processar {zip_file_name}: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14be649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(response: requests.Response, file_name: str, base_dir: str = \"../LND\") -> None:\n",
    "    \"\"\"\n",
    "    Salva os dados de uma resposta JSON da API em um arquivo na estrutura de diretórios da camada LND.\n",
    "\n",
    "    Args:\n",
    "        response (requests.Response): Objeto de resposta da requisição HTTP.\n",
    "        file_name (str): Nome da subpasta e prefixo do arquivo.\n",
    "        base_dir (str): Diretório base onde os dados serão salvos (padrão: \"../LND\").\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: Se a resposta contiver um status HTTP de erro.\n",
    "        ValueError: Se o conteúdo não for um JSON válido.\n",
    "        RequestException: Para outros erros relacionados a requests.\n",
    "        Exception: Para outros erros de escrita/salvamento.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verifica se a resposta HTTP foi bem-sucedida.\n",
    "        # Se o status_code for >= 400, um HTTPError será lançado.\n",
    "        response.raise_for_status()\n",
    "\n",
    "        try:\n",
    "            # Tenta converter o conteúdo da resposta para JSON.\n",
    "            data: Any = response.json()\n",
    "        except json.JSONDecodeError as e:\n",
    "            # Se o conteúdo não for um JSON válido, lança um erro mais descritivo.\n",
    "            raise ValueError(\"Resposta da API não é um JSON válido.\") from e\n",
    "\n",
    "        # Verifica se o JSON retornado é um dicionário ou uma lista.\n",
    "        if not isinstance(data, (dict, list)):\n",
    "            raise ValueError(\"Conteúdo JSON inválido: não é dict nem list.\")\n",
    "\n",
    "        # Gera timestamp para garantir nome único ao arquivo\n",
    "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "        # Cria o caminho onde o arquivo será salvo\n",
    "        path = os.path.join(base_dir, file_name)\n",
    "\n",
    "        # Cria o diretório, se ainda não existir\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # Gera o nome completo do arquivo incluindo timestamp\n",
    "        full_filename = os.path.join(path, f\"{file_name}_{timestamp}.json\")\n",
    "\n",
    "        # Abre o arquivo no modo escrita e salva os dados JSON formatados\n",
    "        with open(full_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "            json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "        print(\n",
    "            f\"Arquivo JSON salvo com sucesso em: {os.path.abspath(full_filename)}\")\n",
    "\n",
    "    # Erro de status HTTP (ex: 404, 500, etc.)\n",
    "    except HTTPError as http_err:\n",
    "        print(f\"[HTTP ERRO] Código {response.status_code}: {http_err}\")\n",
    "        raise\n",
    "\n",
    "    # Falha de rede, servidor não encontrado, timeout, etc.\n",
    "    except (ConnectionError, Timeout) as conn_err:\n",
    "        print(f\"[CONEXÃO ERRO] Falha na comunicação com a API: {conn_err}\")\n",
    "        raise\n",
    "\n",
    "    # Erros genéricos da biblioteca requests\n",
    "    except RequestException as req_err:\n",
    "        print(f\"[REQUEST ERRO] Erro inesperado com a requisição: {req_err}\")\n",
    "        raise\n",
    "\n",
    "    # Qualquer outro erro inesperado\n",
    "    except Exception as e:\n",
    "        print(f\"[X] Erro ao salvar JSON: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c1cde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_rf(month: str = \"2025-06\") -> List[str]:\n",
    "    \"\"\"\n",
    "    Lista os arquivos .zip disponíveis no diretório público da Receita Federal para o mês informado.\n",
    "\n",
    "    A função acessa o diretório HTML dos dados abertos do CNPJ disponibilizados pela Receita Federal\n",
    "    e extrai os nomes dos arquivos .zip disponíveis na pasta do mês especificado.\n",
    "\n",
    "    Args:\n",
    "        month (str, optional): Mês e ano no formato \"YYYY-MM\" que indica a pasta desejada. \n",
    "                               Padrão: \"2025-06\".\n",
    "\n",
    "    Raises:\n",
    "        HTTPError: Se a resposta HTTP indicar erro.\n",
    "        RequestException: Para falhas gerais de conexão ou requisição.\n",
    "        Exception: Para qualquer outro erro não previsto.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Lista contendo os nomes dos arquivos .zip encontrados.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Define a URL base dos dados abertos do CNPJ\n",
    "        base_url = \"https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj\"\n",
    "\n",
    "        # Concatena a URL base com o mês informado para formar o link completo\n",
    "        full_url = f\"{base_url}/{month}/\"\n",
    "\n",
    "        # Faz requisição HTTP para acessar o conteúdo da página HTML da pasta do mês\n",
    "        response = requests.get(full_url)\n",
    "\n",
    "        # Lança erro automático se a resposta for código >= 400 (ex: 404, 500)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Usa BeautifulSoup para interpretar o conteúdo HTML da resposta\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Coleta todos os links <a href=\"...\"> que terminam com \".zip\"\n",
    "        zip_files: List[str] = [\n",
    "            a[\"href\"]\n",
    "            for a in soup.find_all(\"a\", href=True)\n",
    "            if a[\"href\"].endswith(\".zip\")\n",
    "        ]\n",
    "\n",
    "        # Caso nenhum arquivo .zip seja encontrado, informa no terminal\n",
    "        if not zip_files:\n",
    "            print(\n",
    "                f\"[INFO] Nenhum arquivo .zip encontrado para o mês {month} em {full_url}.\"\n",
    "            )\n",
    "\n",
    "        # Retorna a lista de nomes de arquivos .zip encontrados\n",
    "        return zip_files\n",
    "\n",
    "    # Caso a resposta HTTP tenha código de erro (ex: 404), exibe mensagem\n",
    "    except HTTPError as http_err:\n",
    "        print(\n",
    "            f\"[HTTP ERRO] Falha ao acessar {full_url} - Código {response.status_code}: {http_err}\")\n",
    "        raise\n",
    "\n",
    "    # Problemas de conexão ou tempo de espera excedido\n",
    "    except (ConnectionError, Timeout) as conn_err:\n",
    "        print(\n",
    "            f\"[CONEXÃO ERRO] Erro de conexão ao acessar {full_url}: {conn_err}\")\n",
    "        raise\n",
    "\n",
    "    # Erros genéricos da biblioteca requests (DNS, SSL, etc.)\n",
    "    except RequestException as req_err:\n",
    "        print(\n",
    "            f\"[REQUEST ERRO] Erro inesperado na requisição ao acessar {full_url}: {req_err}\")\n",
    "        raise\n",
    "\n",
    "    # Qualquer outro erro inesperado durante a execução\n",
    "    except Exception as e:\n",
    "        print(f\"[X] Erro ao processar listagem de arquivos em {full_url}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a11df",
   "metadata": {},
   "source": [
    "## Coleta dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63622847",
   "metadata": {},
   "source": [
    "- API IBGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b49e34da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo JSON salvo com sucesso em: /home/wilcb/projeto_data_warehouse/LND/municipios/municipios_2025-07-23_223116.json\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    url: str = \"https://servicodados.ibge.gov.br/api/v1/localidades/municipios\"\n",
    "    response: requests.Response = requests.get(url)\n",
    "    save_json(response, \"municipios\")\n",
    "except Exception as e:\n",
    "    print(f\"[FALHA TOTAL] {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404ee57f",
   "metadata": {},
   "source": [
    "- Listar arquivos .zip do site da receita federal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e63657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cnaes.zip\n",
      "Empresas0.zip\n",
      "Empresas1.zip\n",
      "Empresas2.zip\n",
      "Empresas3.zip\n",
      "Empresas4.zip\n",
      "Empresas5.zip\n",
      "Empresas6.zip\n",
      "Empresas7.zip\n",
      "Empresas8.zip\n",
      "Empresas9.zip\n",
      "Estabelecimentos0.zip\n",
      "Estabelecimentos1.zip\n",
      "Estabelecimentos2.zip\n",
      "Estabelecimentos3.zip\n",
      "Estabelecimentos4.zip\n",
      "Estabelecimentos5.zip\n",
      "Estabelecimentos6.zip\n",
      "Estabelecimentos7.zip\n",
      "Estabelecimentos8.zip\n",
      "Estabelecimentos9.zip\n",
      "Motivos.zip\n",
      "Municipios.zip\n",
      "Naturezas.zip\n",
      "Paises.zip\n",
      "Qualificacoes.zip\n",
      "Simples.zip\n",
      "Socios0.zip\n",
      "Socios1.zip\n",
      "Socios2.zip\n",
      "Socios3.zip\n",
      "Socios4.zip\n",
      "Socios5.zip\n",
      "Socios6.zip\n",
      "Socios7.zip\n",
      "Socios8.zip\n",
      "Socios9.zip\n"
     ]
    }
   ],
   "source": [
    "files: List[str] = list_files_rf()\n",
    "print(\"\\n\".join(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784423e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando download de Paises.zip de https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/2025-06/Paises.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baixando Paises.zip: 100%|█████████████████| 2.75k/2.75k [00:00<00:00, 8.04MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo Paises.zip\n",
      "Arquivo extraído e salvo como: ../LND/paises/2025-06/Paises_2025-07-23_212003.csv\n",
      "ZIP removido: Paises.zip\n",
      "Iniciando download de Qualificacoes.zip de https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/2025-06/Qualificacoes.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baixando Qualificacoes.zip: 100%|██████████████| 980/980 [00:00<00:00, 3.13MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo Qualificacoes.zip\n",
      "Arquivo extraído e salvo como: ../LND/qualificacoes/2025-06/Qualificacoes_2025-07-23_212004.csv\n",
      "ZIP removido: Qualificacoes.zip\n",
      "Iniciando download de Simples.zip de https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/2025-06/Simples.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baixando Simples.zip: 100%|██████████████████| 261M/261M [02:33<00:00, 1.70MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo Simples.zip\n",
      "Arquivo extraído e salvo como: ../LND/simples/2025-06/Simples_2025-07-23_212004.csv\n",
      "ZIP removido: Simples.zip\n",
      "Iniciando download de Socios1.zip de https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/2025-06/Socios1.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Baixando Socios1.zip: 100%|████████████████| 49.5M/49.5M [00:29<00:00, 1.66MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo Socios1.zip\n",
      "Arquivo extraído e salvo como: ../LND/socios/2025-06/Socios1_2025-07-23_212245.csv\n",
      "ZIP removido: Socios1.zip\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    \"Cnaes.zip\",\n",
    "    \"Empresas1.zip\",\n",
    "    \"Estabelecimentos1.zip\",\n",
    "    \"Motivos.zip\",\n",
    "    \"Municipios.zip\",\n",
    "    \"Naturezas.zip\",\n",
    "    \"Paises.zip\",\n",
    "    \"Qualificacoes.zip\",\n",
    "    \"Simples.zip\",\n",
    "    \"Socios1.zip\"\n",
    "\"\"\"\n",
    "\n",
    "files = [\n",
    "    \"Paises.zip\",\n",
    "    \"Qualificacoes.zip\",\n",
    "    \"Simples.zip\",\n",
    "    \"Socios1.zip\"\n",
    "]\n",
    "\n",
    "try:\n",
    "    download_and_extract_files(files)\n",
    "except Exception as e:\n",
    "    print(f\"[ERRO] Falha ao baixar e extrair arquivos: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eeb106",
   "metadata": {},
   "source": [
    "## Dados IBGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55a431",
   "metadata": {},
   "source": [
    "Os dados complementares necessários para este projeto — como Natureza Jurídica, CNAE, Simples Nacional, Municípios da Receita, entre outros — não estão disponíveis via API pública. No entanto, podem ser obtidos diretamente no portal da Receita Federal através de arquivos CSV, ou é só fazer o download atráves da função acima.\n",
    "\n",
    "📂 Acesse: [Base CNPJ — Receita Federal (jun/2025)](https://arquivos.receitafederal.gov.br/dados/cnpj/dados_abertos_cnpj/2025-06/)\n",
    "\n",
    "Esses arquivos devem ser considerados parte da **camada Landing (LND)** e posteriormente processados nos notebooks seguintes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f4a84b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
