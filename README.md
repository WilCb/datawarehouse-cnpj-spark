# ğŸ“Š Projeto Data Warehouse com PySpark e Arquitetura MedalhÃ£o

Este repositÃ³rio contÃ©m a atividade prÃ¡tica desenvolvida como parte do treinamento do projeto de **Data Warehouse**, utilizando **Apache Spark 4.0.0**, **Delta Lake** e a **Arquitetura MedalhÃ£o**.

## ğŸ“ Estrutura da Arquitetura MedalhÃ£o

A pipeline foi construÃ­da com base em 4 camadas principais de dados:

- `landing/` â€” Dados brutos coletados diretamente dos arquivos CSV da Receita Federal ou APIs pÃºblicas.
- `raw/` â€” Dados estruturados com schemas definidos e persistidos em Delta Lake.
- `trusted/` â€” Dados enriquecidos, com validaÃ§Ãµes e joins entre dimensÃµes e fatos.


---

## ğŸ§  Conceitos Estudados

- Arquitetura de Dados
  - Data Lakes e Data Warehouses
  - Arquitetura MedalhÃ£o
  - Tabelas Fato e DimensÃ£o
- PySpark
  - Leitura e escrita com Delta Lake
  - TransformaÃ§Ãµes, joins e tratamento de dados
- Delta Lake
  - Versionamento e `time travel`
- Consumo de Dados PÃºblicos
  - API
  - Arquivos CSV do site da Receita Federal

---

## ğŸ› ï¸ Tecnologias Utilizadas

- **Sistema Operacional:** Ubuntu via WSL (Windows Subsystem for Linux)
- **Python:** 3.12+
- **Apache Spark:** 4.0.0
- **Java:** 17
- **Delta Lake:** integrado via `delta-spark`
- **Notebooks:** JupyterLab / Jupyter Notebook

### Principais bibliotecas (requirements.txt)
```txt
pyspark==4.0.0
delta-spark==4.0.0
requests
jupyterlab
ipython
```

## ğŸ““ Notebooks do Projeto

| Notebook                         | DescriÃ§Ã£o                                                                                      |
| -------------------------------- | ---------------------------------------------------------------------------------------------- |
| `01_coleta_dados.ipynb`          | Coleta dos dados pÃºblicos (arquivos CSV e APIs) e armazenamento na camada `landing/`.          |
| `02_preparacao_raw.ipynb`        | Limpeza inicial e escrita dos dados estruturados na camada `raw/`.                             |
| `03_transformacao_trusted.ipynb` | Joins com tabelas dimensÃ£o, enriquecimento e validaÃ§Ã£o de dados. Escrita na camada `trusted/`. |
| `04_analise_resultados.ipynb`    | AnÃ¡lises exploratÃ³rias e exibiÃ§Ã£o de versÃµes com `DESCRIBE HISTORY`.                           |

## ğŸ§© Modelo Dimensional

A tabela fato Ã© composta pelos dados das empresas (CNPJ), e relaciona-se com as seguintes dimensÃµes:

| Tabela Fato | Chave                      | Tabela DimensÃ£o   |
| ----------- | -------------------------- | ----------------- |
| CNPJ        | `codigo_cnae`              | CNAE              |
| CNPJ        | `codigo_municipio`         | MunicÃ­pios (IBGE) |
| CNPJ        | `codigo_natureza_juridica` | Natureza JurÃ­dica |
| CNPJ        | `cnpj`                     | Simples Nacional  |

## ğŸ§ª Versionamento de Dados

- As camadas **RAW** e **TRUSTED** utilizam o formato Delta Lake.

- Foi realizado versionamento de dados com mÃºltiplas escritas (append ou overwriteSchema) para fins de demonstraÃ§Ã£o.

- Uso de **DESCRIBE HISTORY** para explorar alteraÃ§Ãµes e reprocessamentos.

## ğŸ“‚ OrganizaÃ§Ã£o de DiretÃ³rios

```bash
.
â”œâ”€â”€ LND/         # Dados brutos (JSON ou CSV)
â”œâ”€â”€ RAW/             # Dados estruturados (Delta)
â”œâ”€â”€ TRS/         # Dados tratados e confiÃ¡veis (Delta)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_coleta_dados.ipynb
â”‚   â”œâ”€â”€ 02_preparacao_raw.ipynb
â”‚   â”œâ”€â”€ 03_transformacao_trusted.ipynb
â”‚   â””â”€â”€ 04_analise_resultados.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## âœ… Requisitos para execuÃ§Ã£o

Antes de rodar os notebooks:

1. Instale o Java 17 e o Apache Spark 4.0.0 com suporte a Delta Lake.

2. Configure seu ambiente Python com os pacotes listados em requirements.txt.

3. Utilize um terminal Linux (via WSL, se estiver no Windows) para evitar conflitos de dependÃªncia.

4. Ã‰ necessÃ¡rio realizar o download manual dos arquivos CSV atravÃ©s do site do governo (link disponÃ­vel no notebook `01_coleta_de_dados`.ipynb). ApÃ³s o download, os arquivos devem ser salvos conforme a estrutura da camada RAW, criando as pastas necessÃ¡rias conforme demonstrado.

## ğŸ‘¨â€ğŸ’» Autor

Este projeto foi desenvolvido por **Williams Araujo (WilCb)** como parte do **treinamento prÃ¡tico da ResidÃªncia em TIC da UFAL/EASY em parceria com o SENAI/AL**, com foco em **Engenharia de Dados**.

O objetivo desta atividade Ã© **nivelar o conhecimento tÃ©cnico dos residentes**, preparando-os para o desenvolvimento do **projeto real** que serÃ¡ realizado nas etapas seguintes da residÃªncia.

